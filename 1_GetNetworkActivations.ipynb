{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Network Activations for Test Images\n",
    "*Written by Viviane Clay*\n",
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:23:10.568705Z",
     "start_time": "2021-01-08T08:22:50.966099Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np;\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as c_layers\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:23:10.598618Z",
     "start_time": "2021-01-08T08:23:10.588646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data\n",
    "Data set and trained models can be downloaded here: http://dx.doi.org/10.17632/zdh4d5ws2z.2 For the paper a subset of the full test set is used. To do this exclude all folders with [x,x,x,1] which are folders containing images labeled as 'puzzle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:24:52.919538Z",
     "start_time": "2021-01-08T08:24:52.650260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "balancedTestSetPath = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code/BalancedTestSetAll'\n",
    "datagen = ImageDataGenerator()\n",
    "#removed validation_split=0\n",
    "test_bal = datagen.flow_from_directory(balancedTestSetPath, class_mode='sparse',\n",
    "                                       batch_size=1600,shuffle=False,subset=\"training\",target_size=(168,168))\n",
    "# change batch_size to 1600 if also testing for puzzles\n",
    "realLabel = []\n",
    "for c,v in test_bal.class_indices.items():\n",
    "    c_ext = np.fromstring(c[1:-1], dtype=int, sep=', ')\n",
    "    realLabel.append(c_ext)\n",
    "\n",
    "def getRealLabel(labelBatch,RL):\n",
    "    newLB = []\n",
    "    for label in labelBatch:\n",
    "        l = RL[int(label)]\n",
    "        newLB.append(l)\n",
    "    return newLB\n",
    "\n",
    "def getConceptSubset(AllConceptExamples, numExp):\n",
    "    subset = np.random.randint(0,AllConceptExamples.shape[0],numExp)\n",
    "    trainExp = AllConceptExamples[subset]\n",
    "    mask = np.ones(AllConceptExamples.shape, bool)\n",
    "    mask[subset] = False\n",
    "    testExp = AllConceptExamples[mask]\n",
    "    return trainExp,  testExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:27:27.831231Z",
     "start_time": "2021-01-08T08:27:16.301564Z"
    }
   },
   "outputs": [],
   "source": [
    "obs,label = test_bal.next()\n",
    "obs = obs/255\n",
    "y = np.array(getRealLabel(label, realLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 250,  251,  252,  253,  254,  255,  256,  257,  258,  259,  260,\n",
       "         261,  262,  263,  264,  265,  266,  267,  268,  269,  270,  271,\n",
       "         272,  273,  274,  275,  276,  277,  278,  279,  280,  281,  282,\n",
       "         283,  284,  285,  286,  287,  288,  289,  290,  291,  292,  293,\n",
       "         294,  295,  296,  297,  298,  299,  650,  651,  652,  653,  654,\n",
       "         655,  656,  657,  658,  659,  660,  661,  662,  663,  664,  665,\n",
       "         666,  667,  668,  669,  670,  671,  672,  673,  674,  675,  676,\n",
       "         677,  678,  679,  680,  681,  682,  683,  684,  685,  686,  687,\n",
       "         688,  689,  690,  691,  692,  693,  694,  695,  696,  697,  698,\n",
       "         699,  900,  901,  902,  903,  904,  905,  906,  907,  908,  909,\n",
       "         910,  911,  912,  913,  914,  915,  916,  917,  918,  919,  920,\n",
       "         921,  922,  923,  924,  925,  926,  927,  928,  929,  930,  931,\n",
       "         932,  933,  934,  935,  936,  937,  938,  939,  940,  941,  942,\n",
       "         943,  944,  945,  946,  947,  948,  949, 1200, 1201, 1202, 1203,\n",
       "        1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214,\n",
       "        1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225,\n",
       "        1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236,\n",
       "        1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,\n",
       "        1248, 1249, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558,\n",
       "        1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569,\n",
       "        1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580,\n",
       "        1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591,\n",
       "        1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599], dtype=int64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_def = [y[:,0]==1, y[:,0]==2, y[:,0]==3, y[:,0]==4, y[:,1]==1, y[:,2]==1]#y[:,0]==0, \n",
    "np.where(concept_def[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 168, 168, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_obs = np.load('F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\\\test_run\\\\visobs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 168, 168, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_obs = np.load('F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\\\test_run\\\\vecobs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4000, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_obs = vec_obs.reshape(4000,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next visual and vector obs\n",
    "next_vis_obs = []\n",
    "next_vec_obs = []\n",
    "for i in vis_obs[1:]:\n",
    "    next_vis_obs.append(i)\n",
    "for j in vec_obs[1:]:\n",
    "    next_vec_obs.append(j)\n",
    "\n",
    "next_vis_obs = np.array(next_vis_obs)\n",
    "next_vec_obs = np.array(next_vec_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 168, 168, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vec_obs.shape\n",
    "next_vis_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs me last vala remove kr dete haain, cuz it's next doesn't exist in next_obs\n",
    "vis_obs = vis_obs[:-1]\n",
    "vec_obs = vec_obs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_obs.shape\n",
    "vec_obs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Network Activations\n",
    "### Embodied Agent\n",
    "Adapt paths to model checkpoints. Checkpoints can be found in the folder 'data/agent_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:33:57.907197Z",
     "start_time": "2021-01-08T08:33:57.503274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\agent_checkpoints\\TowerF4_Baseline-0\\LearningBrain/model-30100120.cptk\n"
     ]
    }
   ],
   "source": [
    "#external rewards agent\n",
    "ckpt_path_ext = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\\\agent_checkpoints\\TowerF4_Baseline-0\\LearningBrain/model-30100120.cptk'\n",
    "#curious & external rewards agent\n",
    "ckpt_path_extint = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_plus_ext\\LearningBrain/model-36351394.cptk'\n",
    "#curious agent\n",
    "ckpt_path_int = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_minus_ext/model-82450000.cptk'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "def create_global_steps():\n",
    "    \"\"\"Creates TF ops to track and increment global training step.\"\"\"\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False, dtype=tf.int32)\n",
    "    increment_step = tf.assign(global_step, tf.add(global_step, 1))\n",
    "    return global_step, increment_step\n",
    "\n",
    "\n",
    "global_step, increment_step = create_global_steps()\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "vec_obs_size = 8\n",
    "num_layers = 2\n",
    "h_size = 256\n",
    "h_size_vec = 256\n",
    "            \n",
    "visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, 3], dtype=tf.float32,name=\"visual_observation_0\")\n",
    "\n",
    "running_mean = tf.get_variable(\"running_mean\", [vec_obs_size],trainable=False, dtype=tf.float32,initializer=tf.zeros_initializer())\n",
    "running_variance = tf.get_variable(\"running_variance\", [vec_obs_size],trainable=False,dtype=tf.float32,initializer=tf.ones_initializer())\n",
    "\n",
    "def create_vector_observation_encoder(observation_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        hidden_vec = observation_input\n",
    "        for i in range(num_layers):\n",
    "            hidden_vec = tf.layers.dense(hidden_vec, h_size, activation=activation, reuse=reuse,name=\"hidden_{}\".format(i),kernel_initializer=c_layers.variance_scaling_initializer(1.0))\n",
    "    return hidden_vec\n",
    "\n",
    "def create_visual_observation_encoder(image_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n",
    "        conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n",
    "        hidden_vis = c_layers.flatten(conv2)\n",
    "\n",
    "    with tf.variable_scope(scope + '/' + 'flat_encoding'):\n",
    "        hidden_flat = create_vector_observation_encoder(hidden_vis, h_size, activation,num_layers, scope, reuse)\n",
    "    return hidden_flat\n",
    "\n",
    "\n",
    "visual_encoders = []\n",
    "hidden_state, hidden_visual = None, None\n",
    "\n",
    "encoded_visual = create_visual_observation_encoder(visual_in,h_size,swish,num_layers,\"main_graph_0_encoder0\", False)\n",
    "visual_encoders.append(encoded_visual)\n",
    "hidden_visual = tf.concat(visual_encoders, axis=1)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore(sess, ckpt_path_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curiosity Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_minus_ext/model-82450000.cptk\n"
     ]
    }
   ],
   "source": [
    "# curious agent curiosity encodings\n",
    "\n",
    "ckpt_path_int = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_minus_ext/model-82450000.cptk'\n",
    "\n",
    "#curious & external rewards agent\n",
    "ckpt_path_extint = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_plus_ext\\LearningBrain/model-36351394.cptk'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "curiosity_enc_size = 64\n",
    "\n",
    "visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, 3], dtype=tf.float32,name=\"visual_observation_0\")\n",
    "\n",
    "\n",
    "def create_vector_observation_encoder(observation_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        hidden_vec = observation_input\n",
    "        for i in range(num_layers):\n",
    "            hidden_vec = tf.layers.dense(hidden_vec, h_size, activation=activation, reuse=reuse,name=\"hidden_{}\".format(i),kernel_initializer=c_layers.variance_scaling_initializer(1.0))\n",
    "    return hidden_vec\n",
    "\n",
    "def create_visual_observation_encoder(image_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n",
    "        conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n",
    "        hidden_vis = c_layers.flatten(conv2)\n",
    "\n",
    "    with tf.variable_scope(scope + '/' + 'flat_encoding'):\n",
    "        hidden_flat = create_vector_observation_encoder(hidden_vis, h_size, activation,num_layers, scope, reuse)\n",
    "    return hidden_flat\n",
    "\n",
    "def create_curiosity_encoder(visual_in, curiosity_enc_size):\n",
    "        \"\"\".\n",
    "        Used for implementation of ﻿Curiosity-driven Exploration by Self-supervised Prediction\n",
    "        See https://arxiv.org/abs/1705.05363 for more details.\n",
    "        :return: current state visual encoding\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create the encoder ops for current visual input. Note that these encoders are siamese.\n",
    "        encoded_visual = create_visual_observation_encoder(visual_in, curiosity_enc_size,\n",
    "                                                                swish, 1, \"stream_{}_visual_obs_encoder\"\n",
    "                                                                .format(0), False)\n",
    "\n",
    "            \n",
    "        return encoded_visual\n",
    "\n",
    "    \n",
    "\n",
    "visual_encoders = []\n",
    "# encoded_state_list = []\n",
    "\n",
    "\n",
    "encoded_visual = create_curiosity_encoder(visual_in, curiosity_enc_size)\n",
    "# encoded_state_list = create_curiosity_encoder(visual_in, curiosity_enc_size)\n",
    "\n",
    "\n",
    "\n",
    "visual_encoders.append(encoded_visual)\n",
    "hidden_visual = tf.concat(visual_encoders, axis=1)\n",
    "\n",
    "# encoded_state_list.append(hidden_visual)\n",
    "\n",
    "# encoded_state_list.append(encoded_vector_obs)\n",
    "\n",
    "\n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore(sess, ckpt_path_int)\n",
    "# saver.restore(sess, ckpt_path_extint)\n",
    "\n",
    "\n",
    "encInt2 = sess.run(hidden_visual, feed_dict={visual_in: obs})\n",
    "# encExtInt2 = sess.run(hidden_visual, feed_dict={visual_in: obs})\n",
    "\n",
    "np.save(balancedTestSetPath + '/SortedencInt2.npy',encInt2)\n",
    "# np.save(balancedTestSetPath + '/SortedencExtInt2.npy',encExtInt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encInt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:32:58.041611Z",
     "start_time": "2021-01-08T08:32:56.460808Z"
    }
   },
   "outputs": [],
   "source": [
    "encBal = sess.run(hidden_visual, feed_dict={visual_in: obs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(balancedTestSetPath + '/encInt.npy',encBal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:34:01.587357Z",
     "start_time": "2021-01-08T08:33:59.965701Z"
    }
   },
   "outputs": [],
   "source": [
    "#change last line of network code to saver.restore(sess, ckpt_path_ext)\n",
    "encExt = sess.run(hidden_visual, feed_dict={visual_in: obs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(balancedTestSetPath + '/encExt.npy',encExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:33:55.517587Z",
     "start_time": "2021-01-08T08:33:53.978669Z"
    }
   },
   "outputs": [],
   "source": [
    "#change last line of network code to saver.restore(sess, ckpt_path_extint)\n",
    "encExtInt = sess.run(hidden_visual, feed_dict={visual_in: obs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(balancedTestSetPath + '/encExtInt.npy',encExtInt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions vs Ground truth (in curiosity encodings)\n",
    "to check where the error comes from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving encoding states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_minus_ext/model-82450000.cptk\n"
     ]
    }
   ],
   "source": [
    "# curious agent curiosity encodings\n",
    "\n",
    "ckpt_path_int = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_minus_ext/model-82450000.cptk'\n",
    "\n",
    "#curious & external rewards agent\n",
    "ckpt_path_extint = 'F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_plus_ext\\LearningBrain/model-36351394.cptk'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "def create_global_steps():\n",
    "    \"\"\"Creates TF ops to track and increment global training step.\"\"\"\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False, dtype=tf.int32)\n",
    "    increment_step = tf.assign(global_step, tf.add(global_step, 1))\n",
    "    return global_step, increment_step\n",
    "\n",
    "\n",
    "global_step, increment_step = create_global_steps()\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "curiosity_enc_size = 64 #128 for extint\n",
    "vec_obs_size = 8\n",
    "\n",
    "visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, 3], dtype=tf.float32,name=\"visual_observation_0\")\n",
    "next_visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, 3], dtype=tf.float32,name=\"next_visual_observation_0\")\n",
    "vector_in = tf.placeholder(shape=[None, vec_obs_size], dtype=tf.float32, name='vector_observation_0')\n",
    "next_vector_in = tf.placeholder(shape=[None, vec_obs_size], dtype=tf.float32, name='next_vector_observation_0')\n",
    "\n",
    "def create_vector_observation_encoder(observation_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        hidden_vec = observation_input\n",
    "        for i in range(num_layers):\n",
    "            hidden_vec = tf.layers.dense(hidden_vec, h_size, activation=activation, reuse=reuse,name=\"hidden_{}\".format(i),kernel_initializer=c_layers.variance_scaling_initializer(1.0))\n",
    "    return hidden_vec\n",
    "\n",
    "def create_visual_observation_encoder(image_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n",
    "        conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n",
    "        hidden_vis = c_layers.flatten(conv2)\n",
    "\n",
    "    with tf.variable_scope(scope + '/' + 'flat_encoding'):\n",
    "        hidden_flat = create_vector_observation_encoder(hidden_vis, h_size, activation,num_layers, scope, reuse)\n",
    "    return hidden_flat\n",
    "\n",
    "def create_curiosity_encoders(visual_in,next_visual_in,vector_in,next_vector_in,curiosity_enc_size):\n",
    "        \"\"\"\n",
    "        Creates state encoders for current and future observations.\n",
    "        Used for implementation of ﻿Curiosity-driven Exploration by Self-supervised Prediction\n",
    "        See https://arxiv.org/abs/1705.05363 for more details.\n",
    "        :return: current and future state encoder tensors.\n",
    "        \"\"\"\n",
    "\n",
    "#         if vis_obs_size > 0:\n",
    "#             next_visual_in = []\n",
    "#             visual_encoders = []\n",
    "#             next_visual_encoders = []\n",
    "            \n",
    "            # Create input ops for next (t+1) visual observations.\n",
    "#             next_visual_input = self.create_visual_input(self.brain.camera_resolutions[i],\n",
    "#                                                          name=\"next_visual_observation_\" + str(i))\n",
    "#             next_visual_in.append(next_visual_input)\n",
    "\n",
    "            # Create the encoder ops for current and next visual input. Not that these encoders are siamese.\n",
    "        encoded_visual = create_visual_observation_encoder(visual_in, curiosity_enc_size,\n",
    "                                                                swish, 1, \"stream_{}_visual_obs_encoder\"\n",
    "                                                                .format(0), False)\n",
    "\n",
    "        encoded_next_visual = create_visual_observation_encoder(next_visual_in,\n",
    "                                                                     curiosity_enc_size,\n",
    "                                                                     swish, 1,\n",
    "                                                                     \"stream_{}_visual_obs_encoder\".format(0),\n",
    "                                                                     True)\n",
    "#             visual_encoders.append(encoded_visual)\n",
    "#             next_visual_encoders.append(encoded_next_visual)\n",
    "\n",
    "#             hidden_visual = tf.concat(visual_encoders, axis=1)\n",
    "#             hidden_next_visual = tf.concat(next_visual_encoders, axis=1)\n",
    "#             encoded_state_list.append(hidden_visual)\n",
    "#             encoded_next_state_list.append(hidden_next_visual)\n",
    "\n",
    "#         if vec_obs_size > 0:\n",
    "            # Create the encoder ops for current and next vector input. Not that these encoders are siamese.\n",
    "            # Create input op for next (t+1) vector observation.\n",
    "            \n",
    "\n",
    "        encoded_vector_obs = create_vector_observation_encoder(vector_in,\n",
    "                                                                    curiosity_enc_size,\n",
    "                                                                    swish, 2, \"vector_obs_encoder\",\n",
    "                                                                    False)\n",
    "        encoded_next_vector_obs = create_vector_observation_encoder(next_vector_in,\n",
    "                                                                         curiosity_enc_size,\n",
    "                                                                         swish, 2,\n",
    "                                                                        \"vector_obs_encoder\",\n",
    "                                                                         True)\n",
    "#             encoded_state_list.append(encoded_vector_obs)\n",
    "#             encoded_next_state_list.append(encoded_next_vector_obs)\n",
    "\n",
    "\n",
    "#         encoded_state = tf.concat(encoded_state_list, axis=1)\n",
    "#         self.enc_cur_state = tf.identity(encoded_state, name='enc_cur_state')\n",
    "#         encoded_next_state = tf.concat(encoded_next_state_list, axis=1)\n",
    "        return encoded_visual, encoded_next_visual, encoded_vector_obs, encoded_next_vector_obs\n",
    "    \n",
    "\n",
    "visual_encoders = []\n",
    "next_visual_encoders = []\n",
    "encoded_state_list = []\n",
    "encoded_next_state_list = []\n",
    "\n",
    "encoded_visual, encoded_next_visual, encoded_vector_obs, encoded_next_vector_obs = create_curiosity_encoders(visual_in,next_visual_in,vector_in,next_vector_in,curiosity_enc_size)\n",
    "\n",
    "\n",
    "visual_encoders.append(encoded_visual)\n",
    "next_visual_encoders.append(encoded_next_visual)\n",
    "\n",
    "hidden_visual = tf.concat(visual_encoders, axis=1)\n",
    "hidden_next_visual = tf.concat(next_visual_encoders, axis=1)\n",
    "\n",
    "encoded_state_list.append(hidden_visual)\n",
    "encoded_next_state_list.append(hidden_next_visual)\n",
    "\n",
    "#vector obs\n",
    "encoded_state_list.append(encoded_vector_obs)\n",
    "encoded_next_state_list.append(encoded_next_vector_obs)\n",
    "\n",
    "encoded_state = tf.concat(encoded_state_list, axis=1)\n",
    "# enc_cur_state = tf.identity(encoded_state, name='enc_cur_state')\n",
    "encoded_next_state = tf.concat(encoded_next_state_list, axis=1)\n",
    "\n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# saver.restore(sess, ckpt_path_extint)\n",
    "saver.restore(sess, ckpt_path_int)\n",
    "\n",
    "# For ext + int\n",
    "# curiosity_encoding_ExtInt = sess.run(encoded_state, feed_dict={visual_in: vis_obs, next_visual_in: next_vis_obs, \n",
    "#                                                                  vector_in: vec_obs, next_vector_in: next_vec_obs})\n",
    "\n",
    "# curiosity_encoding_nextstate_ExtInt = sess.run(encoded_next_state, feed_dict={visual_in: vis_obs, next_visual_in: next_vis_obs, \n",
    "#                                                                  vector_in: vec_obs, next_vector_in: next_vec_obs})\n",
    "\n",
    "# For int\n",
    "curiosity_encoding_Int = sess.run(encoded_state, feed_dict={visual_in: vis_obs, next_visual_in: next_vis_obs, \n",
    "                                                                 vector_in: vec_obs, next_vector_in: next_vec_obs})\n",
    "\n",
    "curiosity_encoding_nextstate_Int = sess.run(encoded_next_state, feed_dict={visual_in: vis_obs, next_visual_in: next_vis_obs, \n",
    "                                                                 vector_in: vec_obs, next_vector_in: next_vec_obs})\n",
    "\n",
    "\n",
    "np.save('curiosity_encoding_Int.npy',curiosity_encoding_Int)\n",
    "np.save('curiosity_encoding_nextstate_Int.npy',curiosity_encoding_nextstate_Int)\n",
    "\n",
    "# np.save('curiosity_encoding_ExtInt.npy',curiosity_encoding_ExtInt)\n",
    "# np.save('curiosity_encoding_nextstate_ExtInt.npy',curiosity_encoding_nextstate_ExtInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 256)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(curiosity_encoding_nextstate_ExtInt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00367654, -0.27708212, -0.24987513, -0.01284845, -0.2676933 ,\n",
       "       -0.27519462, -0.23386034, -0.00631044, -0.2529201 , -0.2630602 ,\n",
       "       -0.26540604, -0.2591467 , -0.25666052, -0.26759818, -0.27160275,\n",
       "       -0.2776537 , -0.2306562 , -0.22052696, -0.2683818 , -0.01353922,\n",
       "       -0.26763335, -0.03174633, -0.27825394, -0.03178577, -0.27435848,\n",
       "       -0.02467726, -0.24070746, -0.18899806, -0.0331885 , -0.2570049 ,\n",
       "       -0.01087864, -0.27800736, -0.27582473, -0.21213533, -0.01590122,\n",
       "       -0.26669854, -0.01725548, -0.02650894, -0.21572542, -0.24032596,\n",
       "       -0.24241728, -0.2744831 , -0.27536508, -0.22348848, -0.27369907,\n",
       "       -0.01261332, -0.26492476, -0.27843088, -0.25659516, -0.27824628,\n",
       "       -0.1133415 , -0.2577189 , -0.03740476, -0.2650148 , -0.27785304,\n",
       "       -0.24562898, -0.21821555, -0.2739261 , -0.25572857, -0.27845117,\n",
       "       -0.2777181 , -0.25902605, -0.26506665, -0.24935463, -0.26281443,\n",
       "       -0.26471642, -0.27762637, -0.27742586, -0.25887793, -0.00277773,\n",
       "       -0.27111953, -0.26367816, -0.25152978, -0.01638537, -0.27189383,\n",
       "       -0.00533929, -0.26733053, -0.03105812, -0.24859732, -0.02116554,\n",
       "       -0.02858823, -0.01638309, -0.02287351, -0.25706476, -0.03165489,\n",
       "       -0.27759737, -0.27140218, -0.27076265, -0.24745029, -0.27132162,\n",
       "       -0.01582762, -0.00838324, -0.26362976, -0.27481487, -0.05453091,\n",
       "       -0.21678807, -0.23741163, -0.00598699, -0.04150207, -0.27359945,\n",
       "       -0.2651983 , -0.2723568 , -0.05237651, -0.2782388 , -0.00597109,\n",
       "       -0.01616118, -0.27444363, -0.27838758, -0.27185208, -0.27492067,\n",
       "       -0.25155243, -0.26184726, -0.26738578, -0.20533748, -0.26191127,\n",
       "       -0.03282156, -0.26138294, -0.22000323, -0.2751423 , -0.2762264 ,\n",
       "       -0.25558224, -0.23451276, -0.04300695, -0.27708298, -0.23153612,\n",
       "       -0.20816104, -0.2471884 , -0.20894912, -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curiosity_encoding_ExtInt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9395639e-01, -2.1538323e-01, -2.4449641e-01, -2.7351409e-01,\n",
       "       -2.5941759e-01, -2.7187482e-01, -2.7513552e-01, -1.0053566e-01,\n",
       "       -2.2856171e-01, -2.7323657e-01, -3.7801869e-02, -2.6427484e-01,\n",
       "       -2.6737252e-01, -2.5008720e-01, -6.1797039e-03, -6.7955725e-02,\n",
       "       -1.4259106e-01, -2.7057731e-01, -2.6583448e-01, -2.6172015e-01,\n",
       "       -1.6946465e-01, -3.1065980e-02, -2.3008010e-01, -2.7550307e-01,\n",
       "       -2.7095786e-01, -2.6026446e-01, -2.3612602e-01, -2.4449435e-01,\n",
       "       -2.5509989e-01, -1.3877296e-02, -2.5493723e-01, -2.3772399e-01,\n",
       "       -2.6994812e-01, -2.7833155e-01, -7.8720979e-02, -2.7699345e-01,\n",
       "       -1.6600909e-03, -2.6169819e-01, -2.7794048e-01, -2.7799729e-01,\n",
       "       -2.2737677e-01, -2.0436624e-01, -2.6688579e-02, -2.1890354e-01,\n",
       "       -2.7790481e-01, -7.3809922e-02, -1.7890589e-01, -2.7844119e-01,\n",
       "       -2.7421746e-01, -2.1711354e-01, -2.7698117e-01, -2.0790361e-01,\n",
       "       -3.3025265e-02, -1.4478830e-01, -1.4179970e-01, -2.7617061e-01,\n",
       "       -1.6608201e-01, -1.1311158e-01, -8.1193201e-02, -2.7261347e-01,\n",
       "       -1.2244718e-01, -2.7826008e-01, -2.7002215e-01, -2.7632323e-01,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -1.7937917e-32, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -1.8691121e-02, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -3.1484592e-28,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -0.0000000e+00,\n",
       "       -0.0000000e+00, -3.4775469e-36, -0.0000000e+00, -0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curiosity_encoding_nextstate_Int[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Forward/Backward Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.load('F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\\\actions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 1, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array(actions[:-1],dtype=int)\n",
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = actions.reshape(3999,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\Models\\curious_minus_ext/model-82450000.cptk\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key dense/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-98-af8e63c68d9f>\", line 71, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key dense/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key dense/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-af8e63c68d9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1802\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key dense/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-98-af8e63c68d9f>\", line 71, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key dense/bias not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FOR INT CASE\"\"\"\n",
    "encoded_state_int = np.load(\"curiosity_encoding_Int.npy\")\n",
    "encoded_nextstate_int = np.load(\"curiosity_encoding_nextstate_Int.npy\")\n",
    "\n",
    "# encoded_state_int = np.array(encoded_state_int,dtype=float)\n",
    "# encoded_state_int = encoded_state_int.reshape(3999,1,128)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "def create_global_steps():\n",
    "    \"\"\"Creates TF ops to track and increment global training step.\"\"\"\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False, dtype=tf.int32)\n",
    "    increment_step = tf.assign(global_step, tf.add(global_step, 1))\n",
    "    return global_step, increment_step\n",
    "\n",
    "\n",
    "global_step, increment_step = create_global_steps()\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "curiosity_enc_size = 64 #64 for int\n",
    "vec_obs_size = 8\n",
    "curiosity_strength=1.0\n",
    "vis_obs_size = 1\n",
    "\n",
    "encoded_state = tf.placeholder(shape=[None, 128], dtype=tf.float32,name=\"encoded_state\")\n",
    "encoded_next_state = tf.placeholder(shape=[None, 128], dtype=tf.float32,name=\"encoded_next_state\")\n",
    "sel_action = tf.placeholder(shape=[None, 4], dtype=tf.float32,name=\"sel_action\")\n",
    "\n",
    "\n",
    "def create_forward_model(encoded_state, encoded_next_state, selected_action):\n",
    "#         encoded_next_state\n",
    "        \"\"\"\n",
    "        Creates forward model TensorFlow ops for Curiosity module.\n",
    "        Predicts encoded future state based on encoded current state and given action.\n",
    "        :param encoded_state: Tensor corresponding to encoded current state.\n",
    "        :param encoded_next_state: Tensor corresponding to encoded next state.\n",
    "        :param selected_actions: actions taken\n",
    "        \"\"\"\n",
    "        combined_input = tf.concat([encoded_state, selected_action], axis=1)\n",
    "        hidden = tf.layers.dense(combined_input, 256, activation=swish)\n",
    "        # We compare against the concatenation of all observation streams, hence `self.vis_obs_size + int(self.vec_obs_size > 0)`.\n",
    "        pred_next_state = tf.layers.dense(hidden, curiosity_enc_size * (vis_obs_size + int(vec_obs_size > 0)),\n",
    "                                          activation=None)\n",
    "        \n",
    "\n",
    "        squared_difference = 0.5 * tf.reduce_sum(tf.squared_difference(pred_next_state, encoded_next_state), axis=1)\n",
    "        intrinsic_reward = tf.clip_by_value(curiosity_strength * squared_difference, 0, 1)\n",
    "        forward_loss = tf.reduce_mean(tf.dynamic_partition(data=squared_difference,partitions=[0]*3999\n",
    "                                                           ,num_partitions=2)[1])\n",
    "        \n",
    "        return pred_next_state, squared_difference\n",
    "\n",
    "pred_next_states = []\n",
    "forward_losses = []\n",
    "\n",
    "pred_next_state, forward_loss = create_forward_model(encoded_state, encoded_next_state, sel_action)\n",
    "    \n",
    "\n",
    "pred_next_states.append(pred_next_state)\n",
    "forward_losses.append(forward_loss)\n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore(sess, ckpt_path_int)\n",
    "\n",
    "\n",
    "# For int\n",
    "pred_next_states_Int = sess.run(pred_next_states, feed_dict={encoded_state: encoded_state_int, encoded_next_state: encoded_nextstate_int, sel_action: actions})\n",
    "forward_losses_Int = sess.run(forward_losses, feed_dict={encoded_state: encoded_state_int, encoded_next_state: encoded_nextstate_int, sel_action: actions})\n",
    "\n",
    "\n",
    "\n",
    "# np.save(balancedTestSetPath + '/curiosity_encoding_Int.npy',curiosity_encoding_Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_next_states_Int.npy',pred_next_states_Int)\n",
    "np.save('forward_losses_Int.npy',forward_losses_Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4832752, 2.6360366, 2.645959 , ..., 2.5831168, 2.4899285,\n",
       "       2.414308 ], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_next_states_Int[0][-1]\n",
    "np.array(forward_losses_Int[0])\n",
    "forward_losses_Int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FOR EXT + INT CASE\"\"\"\n",
    "encoded_state_extint = np.load(\"curiosity_encoding_ExtInt.npy\")\n",
    "encoded_nextstate_extint = np.load(\"curiosity_encoding_nextstate_ExtInt.npy\")\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "def create_global_steps():\n",
    "    \"\"\"Creates TF ops to track and increment global training step.\"\"\"\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False, dtype=tf.int32)\n",
    "    increment_step = tf.assign(global_step, tf.add(global_step, 1))\n",
    "    return global_step, increment_step\n",
    "\n",
    "\n",
    "global_step, increment_step = create_global_steps()\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "curiosity_enc_size = 128 #64 for int\n",
    "vec_obs_size = 8\n",
    "curiosity_strength=1.0\n",
    "vis_obs_size = 1\n",
    "\n",
    "encoded_state = tf.placeholder(shape=[None, 256], dtype=tf.float32,name=\"encoded_state\")\n",
    "encoded_next_state = tf.placeholder(shape=[None, 256], dtype=tf.float32,name=\"encoded_next_state\")\n",
    "sel_action = tf.placeholder(shape=[None, 4], dtype=tf.float32,name=\"sel_action\")\n",
    "\n",
    "\n",
    "def create_forward_model(encoded_state, encoded_next_state, selected_action):\n",
    "#         encoded_next_state\n",
    "        \"\"\"\n",
    "        Creates forward model TensorFlow ops for Curiosity module.\n",
    "        Predicts encoded future state based on encoded current state and given action.\n",
    "        :param encoded_state: Tensor corresponding to encoded current state.\n",
    "        :param encoded_next_state: Tensor corresponding to encoded next state.\n",
    "        :param selected_actions: actions taken\n",
    "        \"\"\"\n",
    "        combined_input = tf.concat([encoded_state, selected_action], axis=1)\n",
    "        hidden = tf.layers.dense(combined_input, 256, activation=swish)\n",
    "        # We compare against the concatenation of all observation streams, hence `self.vis_obs_size + int(self.vec_obs_size > 0)`.\n",
    "        pred_next_state = tf.layers.dense(hidden, curiosity_enc_size * (vis_obs_size + int(vec_obs_size > 0)),\n",
    "                                          activation=None)\n",
    "        \n",
    "\n",
    "        squared_difference = 0.5 * tf.reduce_sum(tf.squared_difference(pred_next_state, encoded_next_state), axis=1)\n",
    "        intrinsic_reward = tf.clip_by_value(curiosity_strength * squared_difference, 0, 1)\n",
    "        forward_loss = tf.reduce_mean(tf.dynamic_partition(data=squared_difference,partitions=[0]*3999\n",
    "                                                           ,num_partitions=2)[1])\n",
    "        \n",
    "        return pred_next_state, forward_loss\n",
    "\n",
    "pred_next_states = []\n",
    "forward_losses = []\n",
    "\n",
    "pred_next_state, forward_loss = create_forward_model(encoded_state, encoded_next_state, sel_action)\n",
    "    \n",
    "\n",
    "pred_next_states.append(pred_next_state)\n",
    "forward_losses.append(forward_loss)\n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# For extint\n",
    "pred_next_states_ExtInt = sess.run(pred_next_states, feed_dict={encoded_state: encoded_state_extint, encoded_next_state: encoded_nextstate_extint, sel_action: actions})\n",
    "forward_losses_ExtInt = sess.run(forward_losses, feed_dict={encoded_state: encoded_state_extint, encoded_next_state: encoded_nextstate_extint, sel_action: actions})\n",
    "\n",
    "\n",
    "\n",
    "# np.save(balancedTestSetPath + '/curiosity_encoding_Int.npy',curiosity_encoding_Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05881967,  0.05111243,  0.00898644, ..., -0.06855196,\n",
       "        -0.08051717,  0.10800347],\n",
       "       [ 0.06480721,  0.04491611,  0.01369487, ..., -0.0662618 ,\n",
       "        -0.06143788,  0.11779893],\n",
       "       [ 0.04378022,  0.06110382, -0.01006842, ..., -0.06917566,\n",
       "        -0.05532652,  0.12691106],\n",
       "       ...,\n",
       "       [ 0.10704052,  0.09714859,  0.02385978, ..., -0.01954409,\n",
       "        -0.08360283,  0.12029169],\n",
       "       [ 0.06831752,  0.05936614, -0.00956372, ..., -0.07439092,\n",
       "        -0.07589203,  0.10902264],\n",
       "       [ 0.05609108,  0.06606102, -0.00768268, ..., -0.0591695 ,\n",
       "        -0.07701965,  0.12295669]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_next_states_ExtInt[-1]\n",
    "# forward_losses_ExtInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_next_states_ExtInt.npy',pred_next_states_ExtInt)\n",
    "np.save('forward_losses_ExtInt.npy',forward_losses_ExtInt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 11 and 4 for 'mul' (op: 'Mul') with input shapes: [?,11], [?,4].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 11 and 4 for 'mul' (op: 'Mul') with input shapes: [?,11], [?,4].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3a45fbb2dd9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0minverse_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mpred_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_inverse_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_next_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msel_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mpred_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-3a45fbb2dd9c>\u001b[0m in \u001b[0;36mcreate_inverse_model\u001b[1;34m(encoded_state, encoded_next_state, selected_actions)\u001b[0m\n\u001b[0;32m     46\u001b[0m                  for i in range(len(act_size))], axis=1)\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mcross_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_action\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mselected_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0minverse_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_partition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    977\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1211\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   5064\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5065\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 5066\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   5067\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5068\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 11 and 4 for 'mul' (op: 'Mul') with input shapes: [?,11], [?,4]."
     ]
    }
   ],
   "source": [
    "\"\"\"FOR INT CASE\"\"\"\n",
    "encoded_state_int = np.load(\"curiosity_encoding_Int.npy\")\n",
    "encoded_nextstate_int = np.load(\"curiosity_encoding_nextstate_Int.npy\")\n",
    "# encoded_state_int = np.array(encoded_state_int,dtype=float)\n",
    "# encoded_nextstate_int = np.array(encoded_nextstate_int,dtype=float)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "curiosity_enc_size = 64 #64 for int\n",
    "vec_obs_size = 8\n",
    "curiosity_strength=1.0\n",
    "vis_obs_size = 1\n",
    "\n",
    "# Action space: These subspaces are as follows: forward/backward/noop movement, \n",
    "# left/right/no-op movement, \n",
    "# clockwise/counterclockwise rotation of the camera/no-op, \n",
    "# and no-op/jump.\n",
    "act_size = [3,3,3,2]\n",
    "encoded_state = tf.placeholder(shape=[None, 128], dtype=tf.float32,name=\"encoded_state\")\n",
    "encoded_next_state = tf.placeholder(shape=[None, 128], dtype=tf.float32,name=\"encoded_next_state\")\n",
    "sel_action = tf.placeholder(shape=[None, 4], dtype=tf.float32,name=\"sel_action\")\n",
    "\n",
    "\n",
    "def create_inverse_model(encoded_state, encoded_next_state,selected_actions):\n",
    "        \"\"\"\n",
    "        Creates inverse model TensorFlow ops for Curiosity module.\n",
    "        Predicts action taken given current and future encoded states.\n",
    "        :param encoded_state: Tensor corresponding to encoded current state.\n",
    "        :param encoded_next_state: Tensor corresponding to encoded next state.\n",
    "        \"\"\"\n",
    "        combined_input = tf.concat([encoded_state, encoded_next_state], axis=1)\n",
    "        hidden = tf.layers.dense(combined_input, 256, activation=swish)\n",
    "#         if self.brain.vector_action_space_type == \"continuous\":\n",
    "#         pred_action = tf.layers.dense(hidden, act_size, activation=None)\n",
    "#             squared_difference = tf.reduce_sum(tf.squared_difference(self.pred_action, self.selected_actions), axis=1)\n",
    "#             self.inverse_loss = tf.reduce_mean(tf.dynamic_partition(squared_difference, self.mask, 2)[1])\n",
    "#         else:\n",
    "        pred_action = tf.concat(\n",
    "                [tf.layers.dense(hidden, act_size[i], activation=tf.nn.softmax)\n",
    "                 for i in range(len(act_size))], axis=1)\n",
    "        \n",
    "        cross_entropy = tf.reduce_sum(-tf.log(pred_action + 1e-10) * selected_actions, axis=1)\n",
    "        inverse_loss = tf.reduce_mean(tf.dynamic_partition(cross_entropy, [0]*3999, 2)[1])\n",
    "        \n",
    "        return pred_action, inverse_loss\n",
    "\n",
    "pred_actions = []\n",
    "inverse_losses = []\n",
    "\n",
    "pred_action, inverse_loss = create_inverse_model(encoded_state, encoded_next_state, sel_action)\n",
    "\n",
    "pred_actions.append(pred_action)\n",
    "inverse_losses.append(inverse_loss)\n",
    "    \n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# For int\n",
    "pred_actions_Int = sess.run(pred_actions, feed_dict={encoded_state: encoded_state_int, \n",
    "                                                     encoded_next_state: encoded_nextstate_int,\n",
    "                                                    sel_action: actions})\n",
    "inverse_losses_Int = sess.run(inverse_losses, feed_dict={encoded_state: encoded_state_int, \n",
    "                                                     encoded_next_state: encoded_nextstate_int,\n",
    "                                                    sel_action: actions})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26777884, 0.33520216, 0.397019  , 0.27890372, 0.3936167 ,\n",
       "       0.32747957, 0.31436658, 0.3439591 , 0.3416743 , 0.5264839 ,\n",
       "       0.47351614], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_actions_Int[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FOR EXT + INT CASE\"\"\"\n",
    "\n",
    "\n",
    "encoded_state_extint = np.load(\"F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\\\curiosity_encoding_ExtInt.npy\")\n",
    "encoded_nextstate_extint = np.load(\"F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\FastConceptMapping-main\\data\\\\curiosity_encoding_nextstate_ExtInt.npy\")\n",
    "# encoded_state_extint = np.array(encoded_state_int,dtype=float)\n",
    "# encoded_nextstate_extint = np.array(encoded_nextstate_int,dtype=float)\n",
    "from numpy import argmax\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "curiosity_enc_size = 128 #64 for int\n",
    "vec_obs_size = 8\n",
    "curiosity_strength=1.0\n",
    "vis_obs_size = 1\n",
    "\n",
    "# Action space: These subspaces are as follows: forward/backward/noop movement, \n",
    "# left/right/no-op movement, \n",
    "# clockwise/counterclockwise rotation of the camera/no-op, \n",
    "# and no-op/jump.\n",
    "act_size = [3,3,3,2]\n",
    "\n",
    "encoded_state = tf.placeholder(shape=[None, 256], dtype=tf.float32,name=\"encoded_state\")\n",
    "encoded_next_state = tf.placeholder(shape=[None, 256], dtype=tf.float32,name=\"encoded_next_state\")\n",
    "\n",
    "\n",
    "def create_inverse_model(encoded_state, encoded_next_state):\n",
    "        \"\"\"\n",
    "        Creates inverse model TensorFlow ops for Curiosity module.\n",
    "        Predicts action taken given current and future encoded states.\n",
    "        :param encoded_state: Tensor corresponding to encoded current state.\n",
    "        :param encoded_next_state: Tensor corresponding to encoded next state.\n",
    "        \"\"\"\n",
    "        combined_input = tf.concat([encoded_state, encoded_next_state], axis=1)\n",
    "        hidden = tf.layers.dense(combined_input, 256, activation=swish)\n",
    "#         if self.brain.vector_action_space_type == \"continuous\":\n",
    "#         pred_action = tf.layers.dense(hidden, act_size, activation=None)\n",
    "#             squared_difference = tf.reduce_sum(tf.squared_difference(self.pred_action, self.selected_actions), axis=1)\n",
    "#             self.inverse_loss = tf.reduce_mean(tf.dynamic_partition(squared_difference, self.mask, 2)[1])\n",
    "#         else:\n",
    "        pred_action = tf.concat(\n",
    "                [tf.layers.dense(hidden, act_size[i], activation=tf.nn.softmax)\n",
    "                 for i in range(len(act_size))], axis=1)\n",
    "            \n",
    "        return pred_action\n",
    "\n",
    "#         cross_entropy = tf.reduce_sum(-tf.log(self.pred_action + 1e-10) * self.selected_actions, axis=1)\n",
    "#         self.inverse_loss = tf.reduce_mean(tf.dynamic_partition(cross_entropy, self.mask, 2)[1])\n",
    "\n",
    "pred_actions = []\n",
    "\n",
    "\n",
    "pred_action = create_inverse_model(encoded_state, encoded_next_state)\n",
    "    \n",
    "\n",
    "pred_actions.append(pred_action)\n",
    "    \n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# saver.restore(sess, ckpt_path_extint)\n",
    "# saver.restore(sess, ckpt_path_int)\n",
    "\n",
    "\n",
    "# For ext + int\n",
    "pred_actions_ExtInt = sess.run(pred_actions, feed_dict={encoded_state: encoded_state_extint, encoded_next_state: encoded_nextstate_extint})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_actions_ExtInt = np.array(pred_actions_ExtInt).reshape(3999,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_action_argmax = [0]*3999\n",
    "for index,act in enumerate(pred_actions_ExtInt):\n",
    "    \n",
    "        act_1 = argmax(act[0:3])\n",
    "        act_2 = argmax(act[3:6])\n",
    "        act_3 = argmax(act[6:9])\n",
    "        act_4 = argmax(act[9:11])\n",
    "        \n",
    "        pred_action_argmax[index] = [act_1,act_2,act_3,act_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 2, 2, 0],\n",
       " [1, 2, 2, 0],\n",
       " [2, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 2, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 1, 1, 0],\n",
       " [1, 2, 2, 0],\n",
       " [1, 2, 2, 1],\n",
       " [2, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " [1, 0, 2, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(pred_actions_ExtInt).shape\n",
    "# argmax(pred_actions_ExtInt)\n",
    "# pred_actions_ExtInt\n",
    "pred_action_argmax[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cycler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d62238bdeedb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Don't let the original cycler collide with our validating cycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCycler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mccycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cycler'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "plt.hist(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"TopKV2_1:0\", shape=(3,), dtype=float32) Tensor(\"TopKV2_1:1\", shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "logits = pred_actions_ExtInt[0][0]\n",
    "probs = tf.nn.softmax(logits)\n",
    "k = 3 # the first k=2 highest values\n",
    "indices, values = tf.nn.top_k(probs, k=k)\n",
    "print(indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       ...,\n",
       "       [1, 1, 0, 2],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 0, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:31:16.740100Z",
     "start_time": "2021-01-08T08:31:15.914312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv_1/Elu:0\", shape=(?, 41, 41, 16), dtype=float32)\n",
      "Tensor(\"conv_2/Elu:0\", shape=(?, 19, 19, 32), dtype=float32)\n",
      "Tensor(\"reshape/Reshape:0\", shape=(?, 11552), dtype=float32)\n",
      "Tensor(\"dens_1/Mul:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"dens_2/Mul:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"dens_3/Mul:0\", shape=(?, 12800), dtype=float32)\n",
      "Tensor(\"reshape_1/Reshape:0\", shape=(?, 20, 20, 32), dtype=float32)\n",
      "Tensor(\"deconv_1/Elu:0\", shape=(?, 42, 42, 16), dtype=float32)\n",
      "Tensor(\"deconv_3/Elu:0\", shape=(?, 168, 168, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential,Model\n",
    "from tensorflow.python.keras.layers import Conv3D, Conv2D, UpSampling2D,Conv2DTranspose\n",
    "from tensorflow.python.keras.layers import ConvLSTM2D\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Dense,MaxPooling2D,TimeDistributed,Input,concatenate,Flatten,Reshape,LSTM,Lambda\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "inImg = Input(batch_shape=(None,168, 168, 3),name=\"input_1\")\n",
    "conv = Conv2D(filters=16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, name=\"conv_1\")(inImg)\n",
    "print(conv)\n",
    "conv = Conv2D(filters=32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, name=\"conv_2\")(conv)\n",
    "print(conv)\n",
    "flat = Reshape((19*19*32,))(conv)\n",
    "print(flat)\n",
    "dens = Dense(256,activation=swish,kernel_initializer=c_layers.variance_scaling_initializer(1.0), name=\"dens_1\")(flat)\n",
    "print(dens)\n",
    "enc = Dense(256,activation=swish,kernel_initializer=c_layers.variance_scaling_initializer(1.0), name=\"dens_2\")(dens)\n",
    "print(enc)\n",
    "de_dens = Dense(20*20*32,activation=swish,kernel_initializer=c_layers.variance_scaling_initializer(1.0), name=\"dens_3\")(enc)\n",
    "print(de_dens)\n",
    "shaped = Reshape((20, 20, 32))(de_dens)\n",
    "print(shaped)\n",
    "de_conv = Conv2DTranspose(filters=16, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, name=\"deconv_1\")(shaped)\n",
    "print(de_conv)\n",
    "\n",
    "prediction = Conv2DTranspose(filters=3, kernel_size=[8, 8], strides=[4, 4],padding='same',activation=tf.nn.elu, name=\"deconv_3\")(de_conv)\n",
    "print(prediction)\n",
    "model = Model(inputs=inImg, outputs=prediction)\n",
    "\n",
    "model.compile(optimizer='adadelta',loss='mean_squared_error',metrics=['accuracy','mse'])\n",
    "# adapt this path. Trained model is in the folder 'data'\n",
    "model.load_weights('F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Autoencoder/aemodelAdam50E.h5')\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=[model.get_layer('dens_2').output,model.get_layer('deconv_3').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:31:29.128048Z",
     "start_time": "2021-01-08T08:31:24.303448Z"
    }
   },
   "outputs": [],
   "source": [
    "encAE = intermediate_layer_model.predict(obs)\n",
    "encAE = encAE[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:31:42.247032Z",
     "start_time": "2021-01-08T08:31:41.498999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'dense/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_1/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_2/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_3/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_5/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_7/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "Tensor(\"concat_1:0\", shape=(?, 8), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "num_layers = 2\n",
    "h_size = 256\n",
    "h_size_vec = 256\n",
    "            \n",
    "visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, 3], dtype=tf.float32,name=\"visual_observation_0\")\n",
    "labels = tf.placeholder(shape=[None,8], dtype=tf.int64,name=\"labels\")\n",
    "\n",
    "def create_vector_observation_encoder(observation_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        hidden_vec = observation_input\n",
    "        for i in range(num_layers):\n",
    "            hidden_vec = tf.layers.dense(hidden_vec, h_size, activation=activation, reuse=reuse,name=\"hidden_{}\".format(i),kernel_initializer=c_layers.variance_scaling_initializer(1.0))\n",
    "    return hidden_vec\n",
    "\n",
    "def create_visual_observation_encoder(image_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n",
    "        conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n",
    "        hidden_vis = c_layers.flatten(conv2)\n",
    "\n",
    "    with tf.variable_scope(scope + '/' + 'flat_encoding'):\n",
    "        hidden_flat = create_vector_observation_encoder(hidden_vis, h_size, activation,num_layers, scope, reuse)\n",
    "    return hidden_flat\n",
    "\n",
    "visual_encoders = []\n",
    "\n",
    "encoded_visual = create_visual_observation_encoder(visual_in,h_size,swish,num_layers,\"main_graph_0_encoder0\", False)\n",
    "visual_encoders.append(encoded_visual)\n",
    "hidden = tf.concat(visual_encoders, axis=1)\n",
    "\n",
    "out_acts = []\n",
    "for o in range(8):\n",
    "    out_acts.append(tf.layers.dense(hidden, 2, activation=tf.nn.softmax, use_bias=False,kernel_initializer=c_layers.variance_scaling_initializer(factor=0.01)))\n",
    "print(out_acts)\n",
    "\n",
    "output = tf.concat([tf.multinomial(tf.log(out_acts[k]), 1) for k in range(8)], axis=1)#sample outputs from log probdist\n",
    "print(output)\n",
    "#output = tf.round(out_act)\n",
    "#normalized_logits = tf.identity(normalized_logits_flat, name='action')#has nan in places where prob is negative bc it it log(probs)\n",
    "\n",
    "comparison = tf.equal(labels, output)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(comparison, dtype=tf.float32))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:32:03.233778Z",
     "start_time": "2021-01-08T08:32:00.569589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt: Not found: FindFirstFile failed for: F:/STUDY/MS Cognitive Science IITD/Internship/RTG Computational Cognition/Code/zdh4d5ws2z-2/data/data/Classifier/Model_lr0001_scaled : The system cannot find the path specified.\r\n; No such process\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-9358b0218f7d>\", line 77, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt: Not found: FindFirstFile failed for: F:/STUDY/MS Cognitive Science IITD/Internship/RTG Computational Cognition/Code/zdh4d5ws2z-2/data/data/Classifier/Model_lr0001_scaled : The system cannot find the path specified.\r\n; No such process\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt: Not found: FindFirstFile failed for: F:/STUDY/MS Cognitive Science IITD/Internship/RTG Computational Cognition/Code/zdh4d5ws2z-2/data/data/Classifier/Model_lr0001_scaled : The system cannot find the path specified.\r\n; No such process\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5c71e9d64a8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# adapt this path. Trained model is in the folder 'data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1802\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt: Not found: FindFirstFile failed for: F:/STUDY/MS Cognitive Science IITD/Internship/RTG Computational Cognition/Code/zdh4d5ws2z-2/data/data/Classifier/Model_lr0001_scaled : The system cannot find the path specified.\r\n; No such process\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-9358b0218f7d>\", line 77, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\varad srivastava\\anaconda3\\envs\\ml-agents\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt: Not found: FindFirstFile failed for: F:/STUDY/MS Cognitive Science IITD/Internship/RTG Computational Cognition/Code/zdh4d5ws2z-2/data/data/Classifier/Model_lr0001_scaled : The system cannot find the path specified.\r\n; No such process\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "saver.restore(sess, \"F:\\STUDY\\MS Cognitive Science IITD\\Internship\\RTG Computational Cognition\\Code\\zdh4d5ws2z-2\\data\\data\\Classifier\\Model_lr0001_scaled/model.ckpt\")\n",
    "sess.run(init)\n",
    "# adapt this path. Trained model is in the folder 'data'\n",
    "outClass,actClass = sess.run([output,hidden], feed_dict = {visual_in: obs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:44:43.306926Z",
     "start_time": "2021-01-08T08:44:43.277004Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFlatLabel(label2D):\n",
    "    flatLabels = []\n",
    "    for label in label2D:\n",
    "        flatLabel = np.zeros(8)\n",
    "        if label[0] == 0:\n",
    "            flatLabel[0] = 1\n",
    "        elif label[0] == 1:\n",
    "            flatLabel[1] = 1\n",
    "        elif label[0] == 2:\n",
    "            flatLabel[2] = 1\n",
    "        elif label[0] == 3:\n",
    "            flatLabel[3] = 1\n",
    "        elif label[0] == 4:\n",
    "            flatLabel[4] = 1\n",
    "        if label[1] == 1:\n",
    "            flatLabel[5] = 1\n",
    "        if label[2] == 1:\n",
    "            flatLabel[6] = 1\n",
    "        if label[3] == 1:\n",
    "            flatLabel[7] = 1\n",
    "        flatLabels.append(flatLabel)\n",
    "    return np.array(flatLabels)\n",
    "flatL = getFlatLabel(y)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:44:45.232503Z",
     "start_time": "2021-01-08T08:44:43.790200Z"
    }
   },
   "outputs": [],
   "source": [
    "#calculte calssifier stats with same amount of positive as negative examples per concept \n",
    "#to do this negative examples are randomly sampled from all possible negative examples\n",
    "\n",
    "accuracies, precisions, recalls, f1scores = [],[],[],[]\n",
    "for c in range(7):\n",
    "    accuracy, precision, recall, f1score = [],[],[],[]\n",
    "    for i in range(1000):#repeat multiple times to avoid effect of random sampling for negative examples\n",
    "        classIDs = np.where(flatL[:,c]==1)[0]\n",
    "        numExp = np.shape(classIDs)[0]\n",
    "        negExpIDs = np.where(flatL[:,c]==0)[0]\n",
    "        np.random.shuffle(negExpIDs)\n",
    "        negExpIDs = negExpIDs[:numExp]\n",
    "\n",
    "        true_pos = np.sum(outClass[classIDs,c] == flatL[classIDs,c])\n",
    "        true_neg = np.sum(outClass[negExpIDs,c] == flatL[negExpIDs,c])\n",
    "        false_pos = np.sum(outClass[negExpIDs,c] != flatL[negExpIDs,c])\n",
    "        false_neg = np.sum(outClass[classIDs,c] != flatL[classIDs,c])\n",
    "\n",
    "        accuracy.append((true_neg+true_pos)/(numExp*2))\n",
    "        precision.append(true_pos/(true_pos+false_pos))\n",
    "        recall.append(true_pos/(true_pos+false_neg))\n",
    "        f1score.append(2*(precision[i]*recall[i]/(precision[i]+recall[i])))\n",
    "    accuracies.append(np.mean(accuracy)*100)\n",
    "    precisions.append(np.mean(precision)*100)\n",
    "    recalls.append(np.mean(recall)*100)\n",
    "    f1scores.append(np.mean(f1score)*100)\n",
    "classifier_stats = {'Accuracy': np.mean(accuracies),\n",
    "            'Accuracies': np.array(accuracies),\n",
    "            'Precisions': np.array(precisions),\n",
    "            'Recalls': np.array(recalls),\n",
    "            'F1Scores': np.array(f1scores)}\n",
    "classifier_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T08:46:06.661415Z",
     "start_time": "2021-01-08T08:46:06.625511Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save(balancedTestSetPath + 'encExt.npy',encExt)\n",
    "# np.save(balancedTestSetPath + 'encInt.npy',encBal)\n",
    "# np.save(balancedTestSetPath + 'encExtInt.npy',encExtInt)\n",
    "# np.save(balancedTestSetPath + 'encAE.npy',encAE)\n",
    "# np.save(balancedTestSetPath + 'encC.npy',actClass)\n",
    "# np.save(balancedTestSetPath + 'outClass.npy',outClass)\n",
    "np.save(balancedTestSetPath + 'labels.npy',y)\n",
    "np.save(balancedTestSetPath + 'obs.npy',obs)\n",
    "# adapt this path.\n",
    "# figurePath = './Results/TowerTraining/Figures/AgentRewardComparisonsAdaTH/ActivationPatternsNormx2No-01-FlatC-50-50Test/'\n",
    "# np.save(figurePath+'classifier_stats.npy',classifier_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
